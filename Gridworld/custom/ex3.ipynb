{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta = \\{\\psi, \\sigma_1, \\sigma_2\\} $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{\\theta}(s_{t+1}|s_t, a_t) = \\{_{pdf(x_{t+1}, \\; (x_t+a_t^0), \\; \\theta_2) \\; \\times \\; pdf(y_{t+1}, \\; (y_t+a_t^1), \\; \\theta_2) \\; if \\; x_t >= \\theta_0}^{pdf(x_{t+1}, \\; (x_t+a_t^0), \\; \\theta_1) \\; \\times \\; pdf(y_{t+1}, \\; (y_t+a_t^1), \\; \\theta_1) \\; if \\; x_t < \\theta_0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 1), (0, 1)),\n",
       " (array([-0.34205444,  4.67199512]), (0, 1)),\n",
       " (array([2.00900055, 7.3539974 ]), (0, 1)),\n",
       " (array([0.91517047, 8.98834602]), (1, 0)),\n",
       " (array([-1.06423127,  9.08041599]), (1, 0)),\n",
       " (array([3.91629971, 7.77507107]), (0, -1)),\n",
       " (array([5.43637829, 6.96886528]), (0, 1)),\n",
       " (array([ 2.08855394, 11.49389515]), (0, 1)),\n",
       " (array([ 2.00814495, 13.79200844]), (-1, 0)),\n",
       " (array([-1.10101556, 12.45066628]), (0, 1)),\n",
       " (array([ 0.305633  , 11.75713749]), (1, 0)),\n",
       " (array([-1.71662076, 15.03841277]), (0, -1)),\n",
       " (array([-0.09157384, 17.70505487]), (1, 0)),\n",
       " (array([-2.0504338 , 16.62519688]), (0, -1)),\n",
       " (array([-0.0705911 , 14.61297135]), (0, 1)),\n",
       " (array([-3.91738156, 13.07321421]), (0, -1)),\n",
       " (array([-2.64119135, 13.13820198]), (0, 1)),\n",
       " (array([-6.30204161, 17.43672328]), (-1, 0)),\n",
       " (array([-7.44224207, 15.64306467]), (0, 1)),\n",
       " (array([-7.47401813, 15.84847236]), (0, -1)),\n",
       " (array([-7.24300614, 13.06116905]), (1, 0)),\n",
       " (array([-7.87186203, 12.05161202]), (-1, 0)),\n",
       " (array([-10.60618019,  10.34735092]), (1, 0)),\n",
       " (array([-11.58941812,  12.14689517]), (0, 1)),\n",
       " (array([-13.96458266,  10.07785522]), (0, 1)),\n",
       " (array([-15.33991704,  10.32953553]), (-1, 0)),\n",
       " (array([-17.02296072,   6.44122821]), (0, -1)),\n",
       " (array([-12.98895678,   8.61109593]), (1, 0)),\n",
       " (array([-9.49886265,  7.5233838 ]), (1, 0)),\n",
       " (array([-9.54708199, 11.08419553]), (-1, 0)),\n",
       " (array([-10.86704713,  12.89282564]), (1, 0)),\n",
       " (array([-11.74450724,  15.40815858]), (-1, 0)),\n",
       " (array([-11.89782314,  16.64319263]), (-1, 0)),\n",
       " (array([-10.84631432,  17.76791272]), (0, -1)),\n",
       " (array([-10.20388921,  16.03137733]), (0, -1)),\n",
       " (array([-12.51575999,  15.44169438]), (0, 1)),\n",
       " (array([-12.06222651,  14.19291025]), (1, 0)),\n",
       " (array([-12.41228382,  15.84421169]), (-1, 0)),\n",
       " (array([-9.387639  , 14.56671197]), (0, -1)),\n",
       " (array([-5.75314659, 13.44585313]), (0, 1)),\n",
       " (array([-5.73346938, 13.20927214]), (0, 1)),\n",
       " (array([-5.90962059, 13.34402406]), (-1, 0)),\n",
       " (array([-6.73628494, 18.21888941]), (1, 0)),\n",
       " (array([-3.45238554, 18.58636814]), (0, 1)),\n",
       " (array([-2.2247617 , 19.60212977]), (0, 1)),\n",
       " (array([-6.26707032, 20.57111817]), (0, -1)),\n",
       " (array([-6.24993729, 16.96783898]), (0, 1)),\n",
       " (array([-7.04067799, 16.33508008]), (0, -1)),\n",
       " (array([-9.68369048, 17.61552344]), (-1, 0)),\n",
       " (array([-10.02182215,  15.19075032]), (0, -1)),\n",
       " (array([-7.77580809, 13.04375979]), (0, -1)),\n",
       " (array([-9.80392699, 12.98039041]), (1, 0)),\n",
       " (array([-8.00059606, 12.85437212]), (-1, 0)),\n",
       " (array([-10.08430742,  13.89944124]), (-1, 0)),\n",
       " (array([-14.05881552,  17.35313619]), (0, 1)),\n",
       " (array([-10.25236248,  16.09392512]), (0, 1)),\n",
       " (array([-12.43178561,  17.71106467]), (0, 1)),\n",
       " (array([-12.56027658,  17.94882843]), (0, -1)),\n",
       " (array([-14.03307936,  17.02502713]), (0, 1)),\n",
       " (array([-12.81272758,  18.3010509 ]), (-1, 0)),\n",
       " (array([-13.81536736,  19.79922562]), (0, 1)),\n",
       " (array([-13.80372108,  19.53967905]), (-1, 0)),\n",
       " (array([-13.50981822,  17.70648743]), (0, 1)),\n",
       " (array([-15.73969171,  23.5368396 ]), (0, 1)),\n",
       " (array([-12.24244663,  27.10126808]), (0, 1)),\n",
       " (array([-9.59315981, 28.91600256]), (0, 1)),\n",
       " (array([-11.63368818,  27.43767648]), (-1, 0)),\n",
       " (array([-14.05348046,  27.80450006]), (0, 1)),\n",
       " (array([-17.67270011,  28.00301125]), (1, 0)),\n",
       " (array([-13.14473186,  28.35631248]), (0, 1)),\n",
       " (array([-15.17752143,  27.73475694]), (0, -1)),\n",
       " (array([-14.73977309,  26.65922085]), (1, 0)),\n",
       " (array([-13.28630135,  28.00599565]), (1, 0)),\n",
       " (array([-11.63182931,  29.48871739]), (0, -1)),\n",
       " (array([-10.25250134,  31.17265158]), (-1, 0)),\n",
       " (array([-10.82922549,  29.54560431]), (-1, 0)),\n",
       " (array([-11.29178175,  28.89871537]), (0, -1)),\n",
       " (array([-13.91092115,  28.51898649]), (1, 0)),\n",
       " (array([-6.15363121, 30.01101301]), (1, 0)),\n",
       " (array([-2.57921843, 33.59815982]), (0, -1)),\n",
       " (array([-0.84401478, 32.68826451]), (0, 1)),\n",
       " (array([-1.20625316, 31.83695407]), (0, -1)),\n",
       " (array([-4.99164996, 31.44736503]), (1, 0)),\n",
       " (array([-6.68072402, 28.45733738]), (0, 1)),\n",
       " (array([-3.91216688, 28.90039355]), (1, 0)),\n",
       " (array([ 0.54957602, 25.65471925]), (0, 1)),\n",
       " (array([ 2.0579307, 27.4419091]), (0, 1)),\n",
       " (array([-2.05515861, 30.15287023]), (1, 0)),\n",
       " (array([8.33940842e-03, 3.26766307e+01]), (1, 0)),\n",
       " (array([-0.55174046, 29.86620227]), (-1, 0)),\n",
       " (array([ 1.82601714, 29.08140906]), (0, -1)),\n",
       " (array([ 4.81390468, 26.67065934]), (0, 1)),\n",
       " (array([ 2.57673935, 25.8276657 ]), (-1, 0)),\n",
       " (array([ 1.95459947, 23.39764673]), (0, 1)),\n",
       " (array([ 1.96019164, 24.43068828]), (-1, 0)),\n",
       " (array([-1.9551452 , 25.61225876]), (1, 0)),\n",
       " (array([-1.55173321, 23.67907421]), (0, 1)),\n",
       " (array([-0.16998735, 22.59601798]), (0, -1)),\n",
       " (array([-0.73728433, 20.52097063]), (0, 1)),\n",
       " (array([ 0.37307669, 20.54700411]), (0, 1))]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "theta = [5, 2, 4]\n",
    "\n",
    "def transiction(s, a, p=2):\n",
    "    return np.array(s) + np.array(a) + np.random.normal(0, p, 2)\n",
    "\n",
    "def pickModel(s, theta):\n",
    "    psi, *m = theta\n",
    "    x,_ = s\n",
    "    return m[int(x >= psi)]\n",
    "\n",
    "def generate(s, n, theta):   \n",
    "    for _ in range(n):\n",
    "        a = random.choice([(1,0), (-1,0), (0,1), (0,-1)])\n",
    "        yield s, a\n",
    "        s = transiction(s, a, pickModel(s, theta))\n",
    "\n",
    "s_0 = (1,1)\n",
    "O = [(s, a) for (s, a) in generate(s_0, 100, theta)]\n",
    "O"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{\\theta}(s_{t+1}|s_t, a_t) = pdf(x_{t+1}, (x_t+a_t^0), \\theta_2) \\; \\times \\; pdf(y_{t+1}, (y_t+a_t^1), \\theta_2) \\; \\times \\; \\mathbb{I}_{x_t >= \\theta_0} + pdf(x_{t+1}, (x_t+a_t^0), \\theta_1) \\; \\times \\; pdf(y_{t+1}, (y_t+a_t^1), \\theta_1) \\; \\times \\; \\mathbb{I}_{x_t < \\theta_0}$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$p_{\\theta}(s_{t+1}|s_t, a_t) = pdf(x_{t+1}, (x_t+a_t^0), \\theta_2) \\; \\times \\; pdf(y_{t+1}, (y_t+a_t^1), \\theta_2) \\; \\times \\; \\frac{1}{1+e^{\\beta (\\theta_0 - x_t)}}$ <br>\n",
    "$ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\; $\n",
    "$ + \\; pdf(x_{t+1}, (x_t+a_t^0), \\theta_1) \\; \\times \\; pdf(y_{t+1}, (y_t+a_t^1), \\theta_1) \\; \\times \\; (1 - \\frac{1}{1+e^{\\beta (\\theta_0 - x_t)}})$ \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\cal{L}[\\xi | \\theta] = \\sum_{t=0}^{\\mathrm{T}-1} log \\; p_{\\theta}(s_{t+1}|s_t, a_t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-427.0669422682604"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def ll(O, theta, beta=10):\n",
    "    psi, sig1, sig2 = theta\n",
    "    # p = lambda s_, s, a: norm.pdf(s_[0], (np.array(s[0]) + np.array(a[0])), m[int(s[0] >= psi)]) * norm.pdf(s_[1], (np.array(s[1]) + np.array(a[1])), m[int(s[0] >= psi)])\n",
    "    p = lambda x_,y_, x,y, ax,ay: ( \n",
    "        norm.pdf(x_, (x + ax), sig2)  \n",
    "        * norm.pdf(y_, (y + ay), sig2) \n",
    "        * (1/(1 + np.e ** (beta * (psi-x))))\n",
    "        +\n",
    "        norm.pdf(x_, (x + ax), sig1) \n",
    "        * norm.pdf(y_, (y + ay), sig1)\n",
    "        * (1 - (1/(1 + np.e ** (beta * (psi-x)))))\n",
    "    )\n",
    "    return np.sum([np.log(p(*s, *O[t-1][0], *O[t-1][1])) for t,(s,_) in enumerate(O) if 0 < t])\n",
    "\n",
    "ll(O, (5, 2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_theta = 0\n",
    "# best_ll = -np.inf\n",
    "\n",
    "# for psi in range(10):\n",
    "#     for p1 in range(10):\n",
    "#         for p2 in range(10):\n",
    "#             theta = (psi+1, p1+1, p2+1)\n",
    "#             new_ll = ll(O, theta)\n",
    "#             if new_ll > best_ll:\n",
    "#                 best_ll = new_ll\n",
    "#                 best_theta = theta\n",
    "\n",
    "# print(best_theta, best_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like:  tensor(-427.0669, grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.48820096,  7.686308  , -0.15903634], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import normal\n",
    "\n",
    "s = Variable(torch.from_numpy(np.array(O)[:-1,0])).type(torch.FloatTensor)\n",
    "a = Variable(torch.from_numpy(np.array(O)[:-1,1])).type(torch.IntTensor)\n",
    "s_ = Variable(torch.from_numpy(np.array(O)[1:,0])).type(torch.FloatTensor)\n",
    "\n",
    "p = Variable(torch.Tensor([5, 2, 4]), requires_grad=True)\n",
    "\n",
    "# loglike = torch.sum(normal.Normal(s[:,0] + a[:,0], torch.where(s[:,0] >= p[0], p[2], p[1])).log_prob(s_[:,0]) + normal.Normal(s[:,1] + a[:,1], torch.where(s[:,0] >= p[0], p[2], p[1])).log_prob(s_[:,1]))\n",
    "loglike = torch.sum(\n",
    "        torch.log(\n",
    "        torch.exp(normal.Normal(s[:,0] + a[:,0], p[2]).log_prob(s_[:,0]))\n",
    "        * torch.exp(normal.Normal(s[:,1] + a[:,1], p[2]).log_prob(s_[:,1]))\n",
    "        * torch.sigmoid(-10 * (p[0]-s[:,0]))\n",
    "        + \n",
    "        torch.exp(normal.Normal(s[:,0] + a[:,0], p[1]).log_prob(s_[:,0]))\n",
    "        * torch.exp(normal.Normal(s[:,1] + a[:,1], p[1]).log_prob(s_[:,1]))\n",
    "        * (1 - torch.sigmoid(-10 * (p[0]-s[:,0])))\n",
    "    )\n",
    ")\n",
    "\n",
    "loglike.backward()\n",
    "gradiente = p.grad.clone()\n",
    "print('like: ', loglike)\n",
    "# gradiente.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5564, 0.6907, 0.2307], requires_grad=True)\n",
      "tensor([0.5563, 0.6437, 0.2308], requires_grad=True)\n",
      "tensor([0.5562, 0.5846, 0.2309], requires_grad=True)\n",
      "tensor([0.5561, 0.5043, 0.2311], requires_grad=True)\n",
      "loglike  = -1784.8802 p = [0.55612355 0.504261   0.23106764]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import normal\n",
    "\n",
    "s = Variable(torch.from_numpy(np.array(O)[:-1,0])).type(torch.FloatTensor)\n",
    "a = Variable(torch.from_numpy(np.array(O)[:-1,1])).type(torch.IntTensor)\n",
    "s_ = Variable(torch.from_numpy(np.array(O)[1:,0])).type(torch.FloatTensor)\n",
    "\n",
    "p = Variable(torch.randn(3), requires_grad=True)\n",
    "beta = .2\n",
    "\n",
    "while p[1] <= 0 or p[2] <= 0:\n",
    "    p = Variable(torch.randn(3), requires_grad=True)\n",
    "\n",
    "learning_rate = 0.00002\n",
    "e = np.inf\n",
    "for t in range(10000):\n",
    "    print(p)\n",
    "    \n",
    "    loglike = torch.sum(\n",
    "        torch.log(\n",
    "            torch.exp(normal.Normal(s[:,0] + a[:,0], p[2]).log_prob(s_[:,0]))\n",
    "            * torch.exp(normal.Normal(s[:,1] + a[:,1], p[2]).log_prob(s_[:,1]))\n",
    "            * torch.sigmoid(-beta * (p[0]-s[:,0]))\n",
    "            + \n",
    "            torch.exp(normal.Normal(s[:,0] + a[:,0], p[1]).log_prob(s_[:,0]))\n",
    "            * torch.exp(normal.Normal(s[:,1] + a[:,1], p[1]).log_prob(s_[:,1]))\n",
    "            * (1 - torch.sigmoid(-beta * (p[0]-s[:,0])))\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    loglike.backward()\n",
    "    \n",
    "    new_p = p.data - learning_rate * p.grad.data\n",
    "    # print(new_p, p, p.grad.data)\n",
    "    if torch.sum(new_p - p.data) == 0:\n",
    "        break\n",
    "    else:\n",
    "        if not new_p.isnan().any():\n",
    "            p.data = new_p\n",
    "            p.grad.data.zero_()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "print(\"loglike  =\", loglike.data.numpy(), \"p =\", p.data.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
