{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{\\theta}(s_{t+1}|s_t, a_t) = \\{_{pdf(x_{t+1}, \\; (x_t+a_t^0), \\; \\theta_2) \\; \\times \\; pdf(y_{t+1}, \\; (y_t+a_t^1), \\; \\theta_2) \\; if \\; x_t >= \\theta_0}^{pdf(x_{t+1}, \\; (x_t+a_t^0), \\; \\theta_1) \\; \\times \\; pdf(y_{t+1}, \\; (y_t+a_t^1), \\; \\theta_1) \\; if \\; x_t < \\theta_0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 1), (-1, 0)),\n",
       " ((-1.0044556550899455, 2.5110750635543395), (0, 1)),\n",
       " ((-1.9546126352606636, 3.7882751058923954), (-1, 0)),\n",
       " ((-3.491839121199425, 2.940984080296791), (1, 0)),\n",
       " ((0.896809395152534, 0.892995240517521), (1, 0)),\n",
       " ((0.20853468042521905, 1.0678692804397274), (1, 0)),\n",
       " ((-0.29523757020887476, 1.4982501401111097), (1, 0)),\n",
       " ((0.2628925359383549, 1.4302179384062719), (1, 0)),\n",
       " ((3.364851790978209, 2.1709790129032553), (-1, 0)),\n",
       " ((-0.00817241033535332, 2.9724229283627785), (1, 0)),\n",
       " ((0.8333534288326957, 1.632852851417949), (-1, 0)),\n",
       " ((-1.670129786892399, 2.8680177091104504), (1, 0)),\n",
       " ((3.672606141984072, 2.3035917530748717), (0, -1)),\n",
       " ((1.3987286936132528, 3.2548170819228757), (-1, 0)),\n",
       " ((-1.851891299680121, 1.2695756872051283), (0, -1)),\n",
       " ((-3.247097982699901, 2.6932998045088112), (0, -1)),\n",
       " ((-3.7065714342699576, 1.9680212436398568), (0, 1)),\n",
       " ((-1.206567840979889, 1.4152686791196096), (0, 1)),\n",
       " ((-2.2311013034162284, 0.4512263698908565), (1, 0)),\n",
       " ((-3.8573661675479918, 4.564520031434458), (0, -1)),\n",
       " ((-3.051072003747656, 2.697943185008423), (0, -1)),\n",
       " ((-1.1403058553303014, 0.07853600882238543), (1, 0)),\n",
       " ((0.5986370883219948, 2.2769861438287), (1, 0)),\n",
       " ((2.8228199063175112, 3.1272239439891107), (0, -1)),\n",
       " ((1.7324823890205834, 3.8781120532920426), (-1, 0)),\n",
       " ((-0.7151371357612328, 3.0649269966371397), (0, 1)),\n",
       " ((-1.8311323122923542, 3.714530065048483), (1, 0)),\n",
       " ((0.22899829768602054, 3.6684024498870773), (1, 0)),\n",
       " ((0.5818779676241826, 5.496491968926384), (-1, 0)),\n",
       " ((-1.2866911539328747, 6.669867462000701), (0, 1)),\n",
       " ((0.6406376500100979, 8.05724435574244), (0, -1)),\n",
       " ((3.404072617558323, 9.849903461691056), (-1, 0)),\n",
       " ((3.4393890239033955, 9.166857469666422), (1, 0)),\n",
       " ((4.43791951407765, 12.71201060089941), (1, 0)),\n",
       " ((8.750680207534664, 12.98706479651046), (0, 1)),\n",
       " ((10.206587937391081, 14.696385870499682), (1, 0)),\n",
       " ((12.224601325325722, 19.229845150652537), (0, 1)),\n",
       " ((13.388405944236792, 22.3237167340843), (1, 0)),\n",
       " ((18.460452449885018, 18.438954085207556), (-1, 0)),\n",
       " ((16.281223333936772, 14.879708529890074), (-1, 0)),\n",
       " ((10.290733316923138, 14.486242034467194), (0, 1)),\n",
       " ((10.017983838460076, 11.515481831589074), (-1, 0)),\n",
       " ((3.161000395032521, 15.177659713378482), (0, -1)),\n",
       " ((1.4776305229985909, 14.106917630382735), (1, 0)),\n",
       " ((4.283493522332864, 12.58945068714489), (-1, 0)),\n",
       " ((5.794440860992037, 9.846467883936159), (0, 1)),\n",
       " ((0.8661216351090362, 11.872366722498395), (-1, 0)),\n",
       " ((-2.8362437089213373, 9.50825190059047), (1, 0)),\n",
       " ((-2.5374902018685486, 7.453237124711663), (0, 1)),\n",
       " ((-2.244370667423726, 6.390153130700085), (1, 0)),\n",
       " ((-0.9062626678246994, 4.820180777461035), (-1, 0)),\n",
       " ((-1.77150086521468, 4.338787939274578), (0, 1)),\n",
       " ((0.10640086579402763, 6.138962245738849), (-1, 0)),\n",
       " ((-1.8895724515538963, 6.60171665795544), (-1, 0)),\n",
       " ((-2.9111576613945473, 6.518354529673588), (0, 1)),\n",
       " ((-6.077749439179252, 7.6442906989734976), (-1, 0)),\n",
       " ((-7.046558457033659, 9.876635285796118), (-1, 0)),\n",
       " ((-8.94059699350944, 10.104955061251934), (-1, 0)),\n",
       " ((-8.687944962564114, 12.970153804908392), (-1, 0)),\n",
       " ((-7.4004058563715285, 8.54343422281281), (-1, 0)),\n",
       " ((-4.998552233873925, 7.933051396634006), (-1, 0)),\n",
       " ((-6.338629452018759, 8.864593680287586), (1, 0)),\n",
       " ((-6.982935387066265, 9.309255423917218), (1, 0)),\n",
       " ((-7.203842459994742, 12.586727660935898), (0, 1)),\n",
       " ((-4.74628881026705, 12.988582370325414), (0, 1)),\n",
       " ((-2.0846556000059295, 15.45840211588519), (0, 1)),\n",
       " ((-4.62089710506919, 15.65523367518261), (0, -1)),\n",
       " ((-0.05184442294951985, 15.360261841065554), (0, -1)),\n",
       " ((-0.5696055707905749, 16.120389827731042), (0, -1)),\n",
       " ((0.8287341750511386, 16.16749406385099), (0, 1)),\n",
       " ((-0.8797807096146439, 18.983744752139668), (-1, 0)),\n",
       " ((-1.9133218748215455, 16.415680698496327), (0, 1)),\n",
       " ((-2.5778143101238924, 18.878148367556772), (-1, 0)),\n",
       " ((-2.016795866425211, 20.4932252430578), (0, -1)),\n",
       " ((-1.6082881278388683, 20.568641241414408), (0, 1)),\n",
       " ((-4.239587942488088, 20.068830350006298), (-1, 0)),\n",
       " ((-2.601051354914603, 20.101167438454677), (1, 0)),\n",
       " ((-1.416715292733909, 17.883522015358917), (0, 1)),\n",
       " ((-3.678513580074856, 19.160757861488204), (0, 1)),\n",
       " ((-2.4687680748503418, 25.124336378859653), (0, -1)),\n",
       " ((0.06906612312322968, 25.791634393808096), (0, 1)),\n",
       " ((-1.9636239888401845, 29.5865387741543), (-1, 0)),\n",
       " ((-4.842226008995173, 30.250783805825215), (1, 0)),\n",
       " ((-2.1305085550421765, 29.72880288963977), (-1, 0)),\n",
       " ((2.7062403867702534, 26.40548034208312), (1, 0)),\n",
       " ((3.007703761873837, 24.86213596331886), (1, 0)),\n",
       " ((7.345031959413457, 24.763754453802342), (0, -1)),\n",
       " ((11.212363095188266, 20.023267439449207), (1, 0)),\n",
       " ((13.674577228873911, 31.125729663739026), (0, 1)),\n",
       " ((9.571690706909006, 33.47711836855644), (0, -1)),\n",
       " ((3.147200044281468, 29.98538068519944), (1, 0)),\n",
       " ((0.797085648559936, 31.272198269384578), (1, 0)),\n",
       " ((-0.5302254444067125, 30.087036209924932), (-1, 0)),\n",
       " ((-2.6205509941520577, 28.000264533118134), (1, 0)),\n",
       " ((-2.170204551648375, 29.273494483055025), (-1, 0)),\n",
       " ((-0.9856761142123083, 30.616546864912603), (1, 0)),\n",
       " ((-0.7086273204988852, 30.331325166657365), (1, 0)),\n",
       " ((-2.065496848130998, 27.328009532979806), (-1, 0)),\n",
       " ((-3.016785986873589, 27.49143166970143), (0, 1)),\n",
       " ((-2.3781323927605977, 30.388495117103272), (0, -1))]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "theta = [5, (2,4)]\n",
    "\n",
    "def transiction(s, a, p=2):\n",
    "    return tuple(np.array(s) + np.array(a) + np.random.normal(0, p, 2))\n",
    "\n",
    "def pickModel(s, theta):\n",
    "    psi, sigma = theta\n",
    "    x,_ = s\n",
    "    return sigma[int(x >= psi)]\n",
    "\n",
    "def generate(s, n, theta):   \n",
    "    for _ in range(n):\n",
    "        a = random.choice([(1,0), (-1,0), (0,1), (0,-1)])\n",
    "        yield s, a\n",
    "        s = transiction(s, a, pickModel(s, theta))\n",
    "\n",
    "s_0 = (1,1)\n",
    "O = [(s, a) for (s, a) in generate(s_0, 100, theta)]\n",
    "O"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\theta = \\{\\psi, \\sigma \\} $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\psi$: Parametros para definição do modelo que será utilizado em cada estado<br>\n",
    "$\\sigma$: Parametros para cada Modelo $\\{\\sigma_1, \\sigma_2, ...\\}$ <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{\\theta}(s_{t+1}|s_t, a_t) = \\mu(s_{t+1}, s_t, a_t, \\sigma_1) \\; \\times \\; \\beta(s_t) + \\mu(s_{t+1}, s_t, a_t, \\sigma_2) \\; \\times \\; \\beta(s_t) + ...$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$p_{\\theta}(s_{t+1}|s_t, a_t) = \\sum_{i=1}^k \\mu(s_{t+1}, s_t, a_t, \\sigma_i) \\beta(s_t)_i \\;\\;\\;\\;\\; for \\;\\; k = |\\sigma_{\\theta}|$  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mu: S \\times S \\times A \\times \\sigma_{\\theta} \\mapsto [0,1]; \\;\\; \\mu(s', s, a, \\sigma) = pdf(s'_x, (s_x+a_x), \\sigma) \\; \\times \\; pdf(s'_y, (s_y+a_y), \\sigma)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 modelos: Sigmoid\n",
    "\n",
    "$ \\beta: S \\mapsto [0,1]; \\;\\; \\beta(s; \\psi_{\\theta})_i = (i-1) + \\frac{1}{1+e^{\\psi_{s}}}(-1)^{i-1} $;  <br>\n",
    "$ for \\;\\; i = \\{1,2\\} $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### N modelos: Softmax\n",
    "\n",
    "$ \\beta: S \\mapsto [0,1]; \\;\\; \\beta(s; \\psi_{\\theta})_i = argmax[\\frac{e^{\\psi_{s,i}}}{\\sum_{j=1}^k e^{\\psi_{s,j}}}] $;   <br>\n",
    "$ for \\;\\; k = |\\sigma_{\\theta}| \\;\\; ; \\;\\; i=1,...,k $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\cal{L}[\\xi | \\theta] = \\sum_{t=0}^{\\mathrm{T}-1} log \\; p_{\\theta}(s_{t+1}|s_t, a_t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-424.67399909458106"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def ll(O, theta):\n",
    "    psi, sigma = theta\n",
    "\n",
    "    def mi(x_,y_, x,y, ax, ay, sig):\n",
    "        return norm.pdf(x_, (x + ax), sig) * norm.pdf(y_, (y + ay), sig) \n",
    "    def beta(x,_, i):\n",
    "        return i + 1/(1+np.e**(10*(x-psi))) * (-1)**i\n",
    "    def p(s_,s,a):\n",
    "        return np.sum([mi(*s_,*s,*a, sig)*beta(*s, i) for i,sig in enumerate(sigma)])\n",
    "    \n",
    "    return np.sum([np.log(p(st, *O[t-1])) for t,(st,_) in enumerate(O) if t>0])\n",
    "\n",
    "ll(O, (5, (2, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_theta = 0\n",
    "# best_ll = -np.inf\n",
    "\n",
    "# for psi in range(10):\n",
    "#     for p1 in range(10):\n",
    "#         for p2 in range(10):\n",
    "#             theta = (psi+1, (p1+1, p2+1))\n",
    "#             new_ll = ll(O, theta)\n",
    "#             if new_ll > best_ll:\n",
    "#                 best_ll = new_ll\n",
    "#                 best_theta = theta\n",
    "\n",
    "# print(best_theta, best_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-424.6740, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import normal\n",
    "\n",
    "s = Variable(torch.from_numpy(np.array(O)[:-1,0])).type(torch.DoubleTensor)\n",
    "a = Variable(torch.from_numpy(np.array(O)[:-1,1])).type(torch.IntTensor)\n",
    "s_ = Variable(torch.from_numpy(np.array(O)[1:,0])).type(torch.DoubleTensor)\n",
    "\n",
    "# p = torch.nn.parameter.Parameter(torch.Tensor(3).uniform_(1, 10))\n",
    "p = torch.nn.parameter.Parameter(torch.Tensor([5,2,4]))\n",
    "\n",
    "mi = torch.cat([(torch.exp(normal.Normal(s[:,0] + a[:,0], i).log_prob(s_[:,0])) * \n",
    "                 torch.exp(normal.Normal(s[:,1] + a[:,1], i).log_prob(s_[:,1]))\n",
    "               ) for i in p[1:]])\n",
    "beta =  torch.cat((torch.ones(len(O)-1) + torch.sigmoid(-10 * (p[0] - s[:,0])) * (-1)**torch.ones(len(O)-1),\n",
    "                   torch.zeros(len(O)-1) + torch.sigmoid(-10 * (p[0] - s[:,0])) * (-1)**torch.zeros(len(O)-1)\n",
    "                ))\n",
    "p_theta = torch.sum((mi*beta).reshape(2, len(O)-1), 0)\n",
    "ll = torch.sum(torch.log(p_theta))\n",
    "ll\n",
    "# beta.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import normal\n",
    "\n",
    "s = Variable(torch.from_numpy(np.array(O)[:-1,0])).type(torch.DoubleTensor)\n",
    "a = Variable(torch.from_numpy(np.array(O)[:-1,1])).type(torch.IntTensor)\n",
    "s_ = Variable(torch.from_numpy(np.array(O)[1:,0])).type(torch.DoubleTensor)\n",
    "\n",
    "p = torch.nn.parameter.Parameter(torch.Tensor([2,4]))\n",
    "# beta\n",
    "beta_in = nn.Linear(2, 2)\n",
    "beta_out = nn.Linear(2, 2, bias=False)\n",
    "beta_activation_function = nn.Softmax(dim=1)\n",
    "psi = list(beta_in.parameters()) + list(beta_out.parameters())\n",
    "\n",
    "mi = torch.stack([(torch.exp(normal.Normal(s[:,0] + a[:,0], i).log_prob(s_[:,0])) * torch.exp(normal.Normal(s[:,1] + a[:,1], i).log_prob(s_[:,1]))) for i in p],\n",
    "                  dim=1\n",
    "                )\n",
    "beta = beta_out(beta_activation_function(beta_in(s.float())))\n",
    "# p_theta = torch.sum((mi * torch.cat([beta, 1-beta])).reshape(2, len(O)-1), 0)\n",
    "p_theta = torch.sum((mi * beta), 1)\n",
    "ll = torch.sum(torch.log(p_theta))\n",
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([2.2794, 0.1000], requires_grad=True)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import normal\n",
    "import torch.nn as nn\n",
    "\n",
    "def estimate(init_p=None):\n",
    "    s = Variable(torch.from_numpy(np.array(O)[:-1,0])).type(torch.DoubleTensor)\n",
    "    a = Variable(torch.from_numpy(np.array(O)[:-1,1])).type(torch.IntTensor)\n",
    "    s_ = Variable(torch.from_numpy(np.array(O)[1:,0])).type(torch.DoubleTensor)\n",
    "\n",
    "    if init_p is not None:\n",
    "        sigma = torch.nn.parameter.Parameter(torch.tensor(init_p))\n",
    "    else:\n",
    "        sigma = torch.nn.parameter.Parameter(torch.Tensor(2).uniform_(1, 10))\n",
    "\n",
    "    # beta\n",
    "    beta_in = nn.Linear(2, 2)\n",
    "    beta_out = nn.Linear(2, 2, bias=False)\n",
    "    # beta_activation_function = nn.Sigmoid()\n",
    "    beta_activation_function = nn.Softmax(dim=1)\n",
    "    psi = list(beta_in.parameters()) + list(beta_out.parameters())\n",
    "\n",
    "    def loglike():\n",
    "        mi = torch.stack([(torch.exp(normal.Normal(s[:,0] + a[:,0], sig).log_prob(s_[:,0])) * \n",
    "                    torch.exp(normal.Normal(s[:,1] + a[:,1], sig).log_prob(s_[:,1]))\n",
    "                ) for sig in sigma], dim=1)\n",
    "        beta = beta_out(beta_activation_function(beta_in(s.float())))\n",
    "        p_theta = torch.sum((mi * beta), 1)\n",
    "        return -torch.sum(torch.log(p_theta))\n",
    "\n",
    "\n",
    "    # optim = torch.optim.SGD([p], lr=1e-2, momentum=0.9)\n",
    "    optim = torch.optim.SGD(psi+[sigma], lr=1e-2)\n",
    "\n",
    "    for _ in range(1000):\n",
    "        # print(i, p)\n",
    "        ll = loglike()\n",
    "        optim.zero_grad()\n",
    "        ll.backward()\n",
    "        optim.step() \n",
    "\n",
    "        with torch.no_grad():\n",
    "            sigma[:] = sigma.clamp(min=1e-1)\n",
    "\n",
    "    return sigma, lambda x: beta_out(beta_activation_function(beta_in(x.float())))[0]\n",
    "\n",
    "\n",
    "p, beta = estimate()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-44.0586,   6.5992], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta(torch.Tensor([[3,2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
